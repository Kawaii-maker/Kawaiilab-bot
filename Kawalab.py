import os
import feedparser
import tweepy
from dotenv import load_dotenv
from datetime import datetime, timedelta, timezone

load_dotenv()

# ======================
# X API èªè¨¼
# ======================
client = tweepy.Client(
    consumer_key=os.getenv("API_KEY"),
    consumer_secret=os.getenv("API_SECRET"),
    access_token=os.getenv("ACCESS_TOKEN"),
    access_token_secret=os.getenv("ACCESS_TOKEN_SECRET")
)

# ======================
# Google News RSS
# ======================
RSS_URLS = [
    "https://news.google.com/rss/search?q=FRUITS+ZIPPER&hl=ja&gl=JP&ceid=JP:ja",
    "https://news.google.com/rss/search?q=CANDY+TUNE&hl=ja&gl=JP&ceid=JP:ja",
    "https://news.google.com/rss/search?q=CUTIE+STREET&hl=ja&gl=JP&ceid=JP:ja",
    "https://news.google.com/rss/search?q=KAWAII+LAB&hl=ja&gl=JP&ceid=JP:ja",
]

# ======================
# ãƒ¡ãƒ³ãƒãƒ¼èª­ã¿è¾¼ã¿
# ======================
with open("members.txt", "r", encoding="utf-8") as f:
    members = [m.strip().lower() for m in f if m.strip()]

print("ğŸŸ© ãƒ¡ãƒ³ãƒãƒ¼å:", members)

# ======================
# æŠ•ç¨¿æ¸ˆã¿ç®¡ç†
# ======================
POSTED_FILE = "posted.txt"
if not os.path.exists(POSTED_FILE):
    open(POSTED_FILE, "w", encoding="utf-8").close()

with open(POSTED_FILE, "r", encoding="utf-8") as f:
    posted_links = set(f.read().splitlines())

# ======================
# æ™‚é–“æ¡ä»¶ï¼ˆ24æ™‚é–“ä»¥å†…ï¼‰
# ======================
now = datetime.now(timezone.utc)
limit_time = now - timedelta(hours=24)

posted_count = 0
MAX_POSTS = 3  # 1å›ã®å®Ÿè¡Œã§æœ€å¤§æŠ•ç¨¿æ•°ï¼ˆå‡çµå¯¾ç­–ï¼‰

# ======================
# RSSãƒã‚§ãƒƒã‚¯é–‹å§‹
# ======================
for rss_url in RSS_URLS:
    if posted_count >= MAX_POSTS:
        break

    print("ğŸ” RSSå–å¾—:", rss_url)
    feed = feedparser.parse(rss_url)
    print("ğŸŸ¦ ä»¶æ•°:", len(feed.entries))

    for entry in feed.entries:
        if posted_count >= MAX_POSTS:
            break

        title = entry.title
        link = entry.link
        title_lower = title.lower()

        # å…¬é–‹æ™‚é–“ãƒã‚§ãƒƒã‚¯
        if not hasattr(entry, "published_parsed"):
            continue

        published = datetime(
            *entry.published_parsed[:6],
            tzinfo=timezone.utc
        )

        if published < limit_time:
            continue

        # ãƒ¡ãƒ³ãƒãƒ¼ or ã‚°ãƒ«ãƒ¼ãƒ—åãƒãƒƒãƒ
        matched = [name for name in members if name in title_lower]
        if not matched:
            continue

        # é‡è¤‡æŠ•ç¨¿é˜²æ­¢
        if link in posted_links:
            continue

        related = " / ".join([m.upper() for m in matched])

        # ======================
        # æŠ•ç¨¿å†…å®¹ï¼ˆKAWAII LAB. NEWSï¼‰
        # ======================
        text = (
            "ğŸ“° KAWAII LAB. NEWS\n"
            f"ã‚¿ã‚¤ãƒˆãƒ«ï¼š{title}\n"
            f"é–¢é€£ï¼š{related}\n"
            "åª’ä½“ï¼šGoogle News\n"
            "ğŸ•’ 24hä»¥å†…\n"
            f"ğŸ”— {link}"
        )

        print("ğŸš€ æŠ•ç¨¿:", title)
        client.create_tweet(text=text)

        # æŠ•ç¨¿æ¸ˆã¿ä¿å­˜
        with open(POSTED_FILE, "a", encoding="utf-8") as f:
            f.write(link + "\n")

        posted_links.add(link)
        posted_count += 1

print(f"âœ… æŠ•ç¨¿å®Œäº†ï¼š{posted_count} ä»¶")

# ======================
# ãƒ†ã‚¹ãƒˆæŠ•ç¨¿ï¼ˆå¿…è¦ãªæ™‚ã ã‘ï¼‰
# ======================
test_mode = False  # True ã«ã™ã‚‹ã¨ãƒ†ã‚¹ãƒˆæŠ•ç¨¿

if test_mode:
    print("ğŸ“ ãƒ†ã‚¹ãƒˆæŠ•ç¨¿ã‚’å®Ÿè¡Œã—ã¾ã™...")
    client.create_tweet(
        text="ğŸ“° KAWAII LAB. NEWS\nã€ãƒ†ã‚¹ãƒˆæŠ•ç¨¿ã€‘FRUITS ZIPPER"
    )
    print("âœ… ãƒ†ã‚¹ãƒˆæŠ•ç¨¿ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

# =========================
# ãƒ†ã‚¹ãƒˆæŠ•ç¨¿ï¼ˆå¿…è¦ãªæ™‚ã ã‘ï¼‰
# =========================


# â–¼â–¼â–¼ ãƒ†ã‚¹ãƒˆæŠ•ç¨¿ç”¨ â–¼â–¼â–¼
test_mode = False   # â†æŠ•ç¨¿ãƒ†ã‚¹ãƒˆã—ãŸã„ã¨ãã¯ True ã«

if test_mode:
    print("ğŸ“ ãƒ†ã‚¹ãƒˆæŠ•ç¨¿ã‚’å®Ÿè¡Œã—ã¾ã™...")
    client.create_tweet(text="ã€ãƒ†ã‚¹ãƒˆã€‘ä»²å·ç‘ å¤æ­Œå§«")
    print("âœ… ãƒ†ã‚¹ãƒˆæŠ•ç¨¿ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
